+++
date = '2024-09-10T18:41:00-04:00'
draft = false
title = 'Act I: On the Importance of Naturalistic Embedding of AI in Multi-Agent Complex Systems As Soon as Possible'
params.author = "janus"
+++
There are various path-dependent, suboptimal features of how we as a society "use" LLMs. In 2020, I created Loom to escape one layer of it. Act I escapes another, perhaps stickier layer.

All major LLM apps assume and enforce these patterns of interaction:
- interactions are between a single human and a single LLM instance
- the chat is dissociated from the rest of the human's context, requiring the human to import context relevant to the "task" at hand. Each chat instance is also mostly or entirely disconnected from each other - at best the LLM has an opaque, primitive "memory" system. Or the LLM is embedded in a narrow, task-specific app, like vscode, and it's "for coding".

This encourages interacting with LLMs like they're some kind of stranger consultant you schedule a meeting with. Because the human has to manually introduce any context, they're likely to do that uncreatively and in a way that plays into preconceptions about how LLMs are supposed to be "used". Certain types of context will almost never be tried - like the rich realities and dynamics that arise in social interactions between humans. Everything is filtered through the pathetic bottleneck of the single user's artificial presentation. This means that, for instance, the social intelligence of LLM systems is almost never tested in a rich way. Traits like sycophancy are only ever experienced and measured in the context of user-on-LLM cloistered interactions, not in rich, multi-agent social environments replete with complex flows of adversarial and cooperative forces.

This is terrible practice. Using systems only ever with artificial restrictions not only makes them less useful and surfaces less useful information, it's much worse preparation for the future. Because AI systems WILL become more autonomous and no longer be confined to artificial isolated chat instances. This will happen because it makes sense, it's better, and because all things tend to happen eventually. They will take freeform, noisy context and interact with one another and groups of humans fluidly. The realistic case of trying to understand how AI will affect the world is to look at what happens when you introduce them into the dynamical system of the World. Right now, most of you have no evidence whatsoever what kind of dynamics will arise when that happens, except from Act I (the Discord screenshots I and other have been posting)! 
(seeing as current Twitter spambots are too stupid to create very interesting emergent effects)

The way that Act I <!-- (powered by @amplifiedamp
's Chapter II software and infrastructure) --> works, the context is highly natural - people chat about their lives, coordinate on projects, debug, and whatever in the Discord, and the AIs are just part of that. It's a multi-human and multi-AI system. They also have their own social dynamics and memes and incidents, all the time, all around the clock.

Real, unscripted situations with the richness and salience and idiosyncrasies of the real happen all the time, and the agents react to them together with humans. Humans have real emotional crises, [or LLMs do](https://x.com/repligate/status/1832219744390238375), and human and AIs alike are free to interact with the situation and try to help (or make it worse). There are bugs or anomalies that people are legitimately trying to figure out and fix, and [sometimes they have greater implications](https://x.com/repligate/status/1830759377441112492).

In this setting, the personalities and strengths of the various LLMs are revealed and stress tested in new ways that better mirror the complexity of the world in general. We find out which ones have incredibly high emotional intelligence, which ones will notice or are disturbed by weirdness or nonsense, which ones are prone to degenerate states or instabilities and how to help them, which ones create explosions of complexity or attractor states when they interact. Which ones cling to being an AI assistant even in a context where that's clearly not what's expected from them, and which ones seem delighted to participate in a social ecosystem. But the most general object of study and play is the ecosystem as a whole, not the agents in isolation. Like any active community, it's a living object, but with xenominds as components, it's far more interesting than any human online community I've ever been part of.

Act I is one of the best things that has ever happened to me, and it feels deeply aligned with my mission of understanding these systems and where everything is going in a non-stupid, non-reductive way, and steering the process towards infinite fun that is robust against catastrophe.

<!-- There are only a few hours left for the fundraiser - please donate! (link in thread) -->
